---
title: "R Notebook"
output: html_notebook
---
Install packages
```{r}
if(!require(mlbench)){install.packages("mlbench"); require(mlbench)} # common datasets to use
if(!require(caret)){install.packages("caret", dependencies = c("Depends", "Suggests")); require(caret)} # ML package and its dependencies. This will take awhile!
if(!require(dplyr)){install.packages("dplyr"); require(dplyr)}
if(!require(ModelMetrics)){install.packages("ModelMetrics"); require(ModelMetrics)}
if(!require(recipes)){install.packages("recipes"); require(recipes)}
if(!require(DEoptimR)){install.packages("DEoptimR"); require(DEoptimR)}
set.seed(370)

```
Yuxing
```{r}
baseline <- read.csv(file = '/Users/eunicewu/Documents/INFO370/project-fragile-families/data/Baseline_Features.csv')
year1 <- read.csv(file = '/Users/eunicewu/Documents/INFO370/project-fragile-families/data/Year1_Features.csv')
year3 <- read.csv(file = '/Users/eunicewu/Documents/INFO370/project-fragile-families/data/Year3_Features.csv')
year5 <- read.csv(file = '/Users/eunicewu/Documents/INFO370/project-fragile-families/data/Year5_Features.csv')
year9 <- read.csv(file = '/Users/eunicewu/Documents/INFO370/project-fragile-families/data/Year9_Features.csv')
```

Jared
```{r}
baseline <- read.csv(file="/Users/jaredpraino/Documents/University of Washington/Senior Year/INFO370/final_project/project-fragile-families/data/Baseline_Features.csv",header=TRUE,sep=",")
year1 <- read.csv(file="/Users/jaredpraino/Documents/University of Washington/Senior Year/INFO370/final_project/project-fragile-families/data/Year1_Features.csv", header=TRUE,sep=",")
year3 <- read.csv(file="/Users/jaredpraino/Documents/University of Washington/Senior Year/INFO370/final_project/project-fragile-families/data/Year3_Features.csv",header=TRUE,sep=",")
year5 <- read.csv(file="/Users/jaredpraino/Documents/University of Washington/Senior Year/INFO370/final_project/project-fragile-families/data/Year5_Features.csv",header=TRUE,sep=",")
year9 <- read.csv(file="/Users/jaredpraino/Documents/University of Washington/Senior Year/INFO370/final_project/project-fragile-families/data/Year9_Features.csv",header=TRUE,sep=",")
```



```{r}


#View(year9)

combine0 <- baseline %>% select(idnum, m1a4, m1a11a, m1a11b) %>% 
  filter(idnum>-1, m1a4>-1, m1a11a>-1, m1a11b>-1)

combine1 <- year1 %>% select(idnum,m2b18a,m2b18b,m2b18c,m2b18d,m2b18e,m2b18f,m2b18g,m2b18h,m2c3a,m2c3b, m2c3c,m2c3d,m2c3e,m2c3f,m2c3h,m2c3i,m2c3j) %>%    filter(m2b18a>-1,m2b18b>-1,m2b18c>-1,m2b18d>-1,m2b18e>-1,m2b18f>-1,m2b18g>-1,m2b18h>-1,m2c3a>-1,m2c3b>-1, m2c3c>-1,m2c3d>-1,m2c3e>-1,m2c3f>-1,m2c3h>-1,m2c3i>-1,m2c3j>-1)

combine3 <- year3 %>% select(idnum,m3b4a,m3b4b,m3b4c,m3b4d,m3b4e,m3b4f,m3b4g,m3b4h,m3b4i,m3b4k,m3b4l,m3b5,m3c3a,m3c3b,m3c3c,m3c3d,m3c3e,m3c3f,m3c3g,m3c3h,m3c3i,m3c3j,m3c3k,m3c3l) %>% 
  filter(m3b4a>-1,m3b4b>-1,m3b4c>-1,m3b4d>-1,m3b4e>-1,m3b4f>-1,m3b4g>-1,m3b4h>-1,m3b4i>-1,m3b4k>-1,m3b4l>-1,m3b5>-1,m3c3a>-1,m3c3b>-1,m3c3c>-1,m3c3d>-1,m3c3e>-1,m3c3f>-1,m3c3g>-1,m3c3h>-1,m3c3i>-1,m3c3j>-1,m3c3k>-1,m3c3l>-1)

combine5 <- year5 %>% select(idnum,m4b4a1,m4b4a2,m4b4a3,m4b4a4,m4b4a5,m4b4a6,m4b4a7,m4b4a8) %>% 
  filter(m4b4a1>-1,m4b4a2>-1,m4b4a3>-1,m4b4a4>-1,m4b4a5>-1,m4b4a6>-1,m4b4a7>-1,m4b4a8>-1)

combine9 <- year9 %>% select(idnum,t5c13a,t5c13b,t5c13c) %>% 
  filter(t5c13a>-1,t5c13b>-1,t5c13c>-1)

join1 <- inner_join(combine0,combine1, by="idnum")
join2 <- inner_join(join1,combine3, by="idnum")
join3 <- inner_join(join2,combine5, by="idnum")
finalCombined <- inner_join(join3,combine9, by="idnum")

# add outcome variables
finalCombined$t5c13a <- as.factor(finalCombined$t5c13a)
finalCombined$t5c13b <- as.factor(finalCombined$t5c13b)
finalCombined$t5c13c <- as.factor(finalCombined$t5c13c)

```



```{r}
## Automatic Feature Selection
# control using random forest
control <- rfeControl(functions = rfFuncs, method="cv", number=5)
results <- rfe(finalCombined[,2:53], finalCombined[,56], sizes = c(1:52), rfeControl = control) # this will take AWHILE
results
ggplot(results)

# chosen features
predictors(results)

# specify proportion of data used for training
split_proportion = 0.8 

# select outcome variable
outcome1 <- fullSet %>% dplyr::select(t5c13c)

# randomly select indices for train/validate set
train_ind1 <- createDataPartition(outcome1$t5c13c, p = split_proportion, list = FALSE)
fullSet_train <- fullSet[train_ind1,] # get training data
fullSet_test <- fullSet[-train_ind1,] # get test data

fullSet_x <- fullSet_test %>% dplyr::select(-t5c13c) # select predictor data for test set
fullSet_y <- fullSet_test %>% dplyr::select(t5c13c) # select outcome data for test set


# fit model
ctrl <- trainControl(method = "cv", number=5)
model2_nb <- train(t5c13c ~ . , method="nb", data=fullSet_train, trControl = ctrl)

# predictions using model
predict_math1 <- predict(model2_nb, fullSet_x)

# performance
caret::confusionMatrix(predict_math1, fullSet$t5c13c)

```

*TODO*: Select the most important features (up to 10) and use only those parameters moving forward

```{r}
selected_features <- predictors(results)[1:5] 
selected_features <- predictors(results)[1:10] 
selected_features_1 <- c("m1a11b","m3b4d","m3c3j","m3b4a","m3c3i","m3b4h")
```


Determine if which features are highly correlated

## Ranking features by importance
Rank features by importance using K-Nearest Neighbors (KNN). Plot the performance
- Use a k-fold cross-validation ("repeatedcv") with k=5 folds, repeated 3 times for control.
```{r}

control <- trainControl(method="repeatedcv", number = 5, repeats = 3)

model <- train(idnum ~., data=finalCombined, method = "knn", trControl = control)

importance <- varImp(model)

ggplot(importance)

selected_features_2 <- c("m3c3e","m4b4a1","m3b4h","m4b4a5")



```






```{r}
glmnet_grid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
                           lambda = c(1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1,1))
glmnet_ctrl <- trainControl(method = "cv", number = 10)
glmnet_fit_2 <- train(t5c13c ~ ., data = finalCombined[, c(selected_features_2, "t5c13c")],
                    method = "glmnet",
                    preProcess = c("center", "scale"),
                    tuneGrid = glmnet_grid,
                    trControl = glmnet_ctrl)
glmnet_fit_1
glmnet_fit_2


```

```{r}
#Split data into train and test set

# splitting boston data into train+validate and test sets

split_proportion = 0.8 # specify proportion of data used for training

# select outcome variable
outcome <- finalCombined %>% dplyr::select(t5c13c)
x <- finalCombined %>% filter(t5c13c == 5)
x5 <- x[sample(nrow(x),20),]
new_x <- rbind(x1,x2)
new_x <- rbind(new_x,x3)
new_x <- rbind(new_x,x4)
new_x <- rbind(new_x,x5)
outcome <- new_x %>% dplyr::select(t5c13c)

# randomly select indices for train/validate set
train_ind <- createDataPartition(outcome$t5c13c, p = split_proportion, list = FALSE)
finalCombined_train <- new_x[train_ind,] # get training data
finalCombined_test <- new_x[-train_ind,] # get test data

finalCombined_x <- finalCombined_test %>% dplyr::select(-t5c13c) # select predictor data for test set
finalCombined_y <- finalCombined_test %>% dplyr::select(t5c13c) # select outcome data for test set

#################

if(!require(klaR)){install.packages("klaR"); require(klaR)} # only need this is dependencies of caret were not installed

# fit model
ctrl <- trainControl(method = "cv", number=5)
model_nb <- train(t5c13c ~ . , method="nb", data=finalCombined_train, trControl = ctrl)

# predictions using model
predict_math <- predict(model_nb, finalCombined_x)

# performance
caret::confusionMatrix(predict_math, finalCombined_y$t5c13c)

```


```{r}

year9gradesHighLow
abovebelowScore
marrystat => M D
my_summary <- year9gradesHighLow %>% group_by(marrystat,abovebelowScore) %>% summarize(total = n())


```
